{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNoC8Dxwq9xb"
   },
   "source": [
    "# Introdução Machine Learning - Data ICMC-USP\n",
    "\n",
    "## Tarefa Aula 01 - k-Nearest Neighbors\n",
    "\n",
    "Esse material foi desenvolvido pelo **Data**, grupo de extensão de aprendizado e ciência de dados compostos por alunos do Instituto de Ciências Matemáticas e de Computação da USP\n",
    "\n",
    "Para saber mais sobre as atividades do Data entre no nosso site e nos siga e nossas redes sociais:\n",
    "- [Site](http://data.icmc.usp.br/)\n",
    "- [Twitter](https://twitter.com/data_icmc)\n",
    "- [LinkedIn](https://www.linkedin.com/school/data-icmc/)\n",
    "- [Facebook](https://www.facebook.com/dataICMC/)\n",
    "\n",
    "Aproveite o material!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vMKesbQkq9xd"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a9270f70bc97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G-iGlBQq9xe"
   },
   "source": [
    "Vamos começar carregando os dados que iremos usar no nossa tarefa. Esses dados fornecem várias informações a respeito de diferentes vinhos e o objetivo é classificar se o vinho é bom (target é a coluna *is_good*).\n",
    "\n",
    "Esse conjunto de dados é uma modificação do conjunto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ts9ZUEcWq9xe"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-215d786f65a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m##############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m##############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "#                       PREENCHA AQUI:                       #\n",
    "#  - Leia os dados de data.csv com pd.read_csv e guarde      #\n",
    "# na variável df                                             #\n",
    "##############################################################\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "##############################################################\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2V29bVLq9xf"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                       PREENCHA AQUI:                       #\n",
    "#  - Guarde o shape do DataFrame na viarável  shape          #\n",
    "##############################################################\n",
    "\n",
    "shape = None\n",
    "\n",
    "##############################################################\n",
    "\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rS47mX8q9xf"
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCbOWdYWq9xg"
   },
   "source": [
    "### Deixando os dados na mesma escala\n",
    "Para vários algoritmos é importante deixarmos os dados em uma mesma escala, e o kNN um desses casos. Para entender melhor vamos olhar o exemplo a seguir:\n",
    "\n",
    "<img src=\"grafico_escala.png\" style=\"width: 400px\"/>\n",
    "\n",
    "Nesse caso a distância entre os dois pontos é dada por\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{dist}(x^{(1)}, x^{(2)}) &= \\sqrt{(x^{(1)}_1 - x^{(2)}_1)^2 + (x^{(1)}_2 - x^{(2)}_2)^2} \\\\\n",
    "  &= \\sqrt{(3 - 2)^2 + (10000 - 9000)^2} \\\\\n",
    "  &= \\sqrt{1 + 1000000} \\\\\n",
    "  &= \\sqrt{1000001} \\\\\n",
    "  &= 1000.0005\n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "Como as escalas são muito diferentes o primeiro atributo acaba não interferindo em praticamente nada no resultado da distância. E é importante perceber que esse tipo de situação ocorre com frequência em conjuntos de dados reais.\n",
    "\n",
    "Existem diversas formas de tratar essa situação, aqui usaremos uma técnica chamada **Min-Max Scaling**, que transforma os dados deixando-os no intervalo $[0, 1]$. A formula é da transformação é a seguinte:\n",
    "\n",
    "$$x^{(i)}_j \\leftarrow \\frac{x^{(i)}_j - min(x_j)}{max(x_j) - min(x_j)}$$\n",
    "\n",
    "Em palavras significa que vamos subtrair o menor valor da atributo e dividir pela amplitude (diferença entre o máximo e o mínimo).\n",
    "\n",
    "\n",
    "Pronto, agora que entendemos podemos fazer fazer isso para todas as nossas colunas utilizando a função interna do scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVLA46avq9xh"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                       PREENCHA AQUI:                       #\n",
    "# - Use MinMaxScaler implementada na Scikit-learn            #\n",
    "#   para escalonar os dados                                  #\n",
    "##############################################################\n",
    "scaler = None\n",
    "##############################################################\n",
    "\n",
    "# Vamos dar uma olhada no resultado do escalonamento\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gup4P33hq9xh"
   },
   "source": [
    "### Divisão dos dados em treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ou99-sF4q9xi"
   },
   "outputs": [],
   "source": [
    "target = 'is good'\n",
    "features = df.columns.to_list()\n",
    "features.remove(target)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df[features], df[target], test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJn7NuBPq9xj"
   },
   "source": [
    "### Treinando um modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T91n6rgqq9xj"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                       PREENCHA AQUI:                       #\n",
    "#  - Instancie um KNeighborsClassifier na variável clf       #\n",
    "#  - Treine o classificador com X_train e y_train            #\n",
    "#  - Faça a predições para os dados de validade e salve      #\n",
    "# em y_pred                                                  #\n",
    "##############################################################\n",
    "\n",
    "clf = None\n",
    "y_pred = None\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLTrACbEq9xj"
   },
   "source": [
    "### Avaliando o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyTbRUyNq9xj"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                       PREENCHA AQUI:                       #\n",
    "#  - Calcule a acurácia do modelo que você treinou usando a  #\n",
    "# função accuracy_score, salve o resultado e o imprima       #\n",
    "##############################################################\n",
    "\n",
    "acc = None\n",
    "\n",
    "##############################################################\n",
    "\n",
    "print(f'A acurácia foi de {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iob7w1yKq9xk"
   },
   "source": [
    "### Explorando variações no modelo\n",
    "\n",
    "#### Número de vizinhos\n",
    "\n",
    "O principal hiperparâmetro do kNN é justamente o número de vizinhos, representado pelo k. Por padrão o `KNeighborsClassifier()` usa cinco vizinhos, através de seu parâmetro `n_neighbors` é possível alterar este valor.\n",
    "\n",
    "#### Métrica de distância\n",
    "\n",
    "Como vimos na aula, é possível utilizar diferentes metricas de distancia entre pontos, e vimos as duas seguintes:\n",
    "\n",
    "- Distância Euclidiana => $dist(a, b) = \\sqrt{\\sum_i (a_i - b_i)^2}$\n",
    "- Distância Manhattan => $dist(a, b) = \\sum_i |a_i - b_i|$\n",
    "\n",
    "O sklearn, por outro lado, faz uso de uma generalização destas duas distâncias, chamada distância **Minkowski** =>\n",
    "$dist(a, b) = (\\sum_i |a_i - b_i|^p)^\\frac{1}{p}$. Perceba que com $p=2$ temos a distância Euclidiano e com $p=1$ temos a distância Manhattan. \n",
    "\n",
    "Por padrão a classe `KNeighborsClassifier()` usa `p=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpgzU1guq9xk"
   },
   "outputs": [],
   "source": [
    "n_vizinhos = [3, 5, 7, 9, 11, 13]\n",
    "resultados = []\n",
    "\n",
    "for k in n_vizinhos:\n",
    "    ##############################################################\n",
    "    #                       PREENCHA AQUI:                       #\n",
    "    #  - Crie um kNN com k vizinhos e utilizando distância       #\n",
    "    # Manhattan                                                  #\n",
    "    # - Treine esse modelo com X_train e y_train                 #\n",
    "    # - Calcule a acurácia do modelo que você treinou e salve    #\n",
    "    # o resultado na lista resultados                            #\n",
    "    ##############################################################\n",
    "    \n",
    "\n",
    "    ##############################################################\n",
    "\n",
    "for k, acc in zip(n_vizinhos, resultados):\n",
    "    print(f'{k:02d} vizinhos => Acurácia {acc * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tarefa.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
